%#####################################################################################################################
% Datei	: Experimental.tex
% Autor	: Byron Worms
%#####################################################################################################################
%---------------------------------------------------------------------------------------------------------------------
% Experimental Investigation
%---------------------------------------------------------------------------------------------------------------------
\section{Experimentelle Untersuchungen}
\label{sec:experimental}
Die theoretische Definition und Beschreibung der einzelnen Algorithmen bieten keine Möglichkeiten Rückschlüsse über die generelle
Einsetzbarkeit in Abhängigkeit des verwendeten Bildmaterials zu ziehen. Aufgrund der hohen Komplexität und Varianz in
den bildlichen Strukturen, können keine allgemeingültigen Aussagen über den Zusammenhang zwischen fehlerhaften Ergebnissen
der Verfahren und dem strukturellen Aufbau der Bilder getroffen werden.
\\
Mit Hilfe der in Abschnitt~\ref{sec:solution} (\textit{Lösungsansatz}) wohldefinierten Kategorien variierenden
Bildmaterials, in Bezug auf Komplexität sowie Strukturaufbau, soll neben der Protokollierung der Stärken und Schwächen der
Algorithmen eine potentielle Korrelation zwischen den strukturellen Gegebenheiten und den grundlegenden Funktionsweisen der
Ansätze untersucht werden.
\\[1em]
Die nachfolgende Auflistung beinhaltet eine Übersicht der durchgeführten und in Kategorien gruppierten Experimente:
\begin{enumerate}[noitemsep]
	\item \boldtext{Fundamentale Funktionalitätstests}
		\begin{itemize}[noitemsep]
			\item Erkennungsraten bei Identitätstests
			\item Erkennungsraten der \textit{Einfachen Farben} \\
		\end{itemize}
	\item \boldtext{Vertiefte Funktionalitätsanalysen}
		\begin{itemize}[noitemsep]
			\item Originalbild vs. Modifikationen (\textit{Elementare Formen})
			\item Originalbild vs. Modifikationen (\textit{Komplexe Bilder})
			\item Erkennungsraten beim Quervergleich der Kategorie \textit{Komplexe Bilder}
		\end{itemize}		
		
	\item \boldtext{Geschwindigkeitsanalysen}
		\begin{itemize}[noitemsep]
			\item Berechnungszeiten der Algorithmen
			\item Kreuzkorrelation mit vollständigem Informationsraum
		\end{itemize}
\end{enumerate}
\noindent
In Abhängigkeit des betrachteten Experiments werden die Fehlerraten \textit{FAR} sowie \textit{FRR} als ein Maß
der Qualität innerhalb der ersten beiden Testgruppen verwendet. Die Geschwindigkeit betreffenden Analysen verwenden
für die qualitative Bewertung der einzelnen Testparameter dahingegen die benötigte Zeit in Sekunden.

\boldtext{Testsystem und Parametrisierung}\\
Für die Gewährleistung, dass die einzelnen Experimente in weitestgehend system-- sowie hardwareunabhängigen Ergebnissen resultieren,
geschieht deren Durchführung ausschließlich auf dem in Tabelle~\ref{tab:experimental_testsystem} beschriebenen System:
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|l|}
			\mytoprule
			%---------------------------------------------------------------------------------------------------------------------	
			Betriebssystem & Windows 8.1, x64
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			Prozessor & AMD x6 1055t (~3.3GHz)
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			RAM & 8GB DDR3
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			Festplatte & SamsungSSD 850 EVO 512GB
			\\																			
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Testsystem (Eigene Darstellung)}
		\label{tab:experimental_testsystem}
	\end{center}
\end{table}	
\noindent
Die Parametrisierung der unterschiedlichen Algorithmen erfolgt nach den in der Bibliothek \textit{pHash} angegebenen Standardwerten:
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|l|}
			\mytoprule
			\centering\bfseries Algorithmus & \bfseries Parameter(--typ)
			\\
			\hline
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			RADISH & Gamma: 1 \\
			& Sigma: 2 \\
			& \#Winkel: 180
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			DCT & --
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			Wavelet & Alpha: 2 \\
			& Level: 1
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			BMB & Methode: 1
			\\																			
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Parametrisierung der Algorithmen (nach~\cite{PHASH})}
		\label{tab:experimental_params}
	\end{center}
\end{table}	
\noindent

\subsection{Fundamentale Funktionalitätstests}
Der Bereich der konstitutiven Funktionalitätstests dient der Protokollierung von grundlegenden (und vorausgesetzten) internen
Arbeitsweisen der zu betrachtenden Algorithmen.

\subsubsection{Erkennungsraten bei Identitätstests}
\label{sec:experimental_selftests}
Die Durchführung des Identitätstests dient als erforderliche Grundlage für alle nachfolgenden aufgestellten Testfälle und wird
daher für alle vier Algorithmen realisiert. Während der Ausführung werden die Bilder aus den Kategorien \textit{Elementare Formen}
sowie \textit{Komplexe Bilder} gegen die eigene Identität verglichen und die eventuell entstehenden Fehler protokolliert.
\\
Das Experiment umfasst insgesamt 288 unterschiedliche Bilddaten und führt zu dem nachstehenden Ergebnis:
\begin{equation*}
	FRR = 0
\end{equation*}
\noindent
Daraus lässt sich schlussfolgern, dass die vier Ansätze für die Berechnung von Perceptual Hashes mit einer hohen Wahrscheinlichkeit
eine deterministische Vorgehensweise inhärieren. Für eine absolute Sicherheit ist hingegen ein formaler Beweis notwendig, der aufgrund der Komplexität
nicht im Rahmen des vorliegenden Papers abgedeckt werden kann.

\subsubsection{Erkennungsraten der \textit{Einfachen Farben}}
Im Experiment wird ein Quervergleich aller neun einfarbigen Bilder der Kategorie \textit{Einfache Farben} mittels der vier Verfahren durchgeführt.
Die entstehenden Resultate basieren dabei auf der Natur der internen Funktionsweise der Vergleichsalgorithmen für die Hashdaten
(eine detaillierte Erläuterung erfolgt in Abschnitt~\ref{sec:results} (\textit{Testergebnisse})).
\\
Der Test beinhaltet 45 Vergleichsmöglichkeiten und generiert das folgende Ergebnis:
\begin{equation*}
	FRR = 1, FAR = 1
\end{equation*}

\subsection{Vertiefte Funktionalitätsanalysen}
Mit Hilfe der nachstehenden Experimente werden Untersuchungen bezüglich der Erkennungsstabilität bei Modifikationen des
Originalbildmaterials und der Detektierung von fälschlich als ähnlich markierten Vergleichspaaren dargelegt. 

\subsubsection{Originalbild vs. Modifikationen (\textit{Elementare Formen})}
\label{sec:experimental_origvsmod_brushes}
Dieser Test analysiert die Robustheit der Algorithmen hinsichtlich der Bilder sowie deren Modifikationen aus der Kategorie
\textit{Elementare Formen}.
Die Durchführung des Tests erfolgt wie nachstehend:
\begin{itemize}[noitemsep]
	\item Originalbilder vs. Verkleinerungen des Originals
	\item Originalbilder vs. Vergrößerungen des Originals
	\item Originalbilder vs. Rotationen des Originals
	\item Originalbilder vs. Gamma--Angleichungen des Originals
	\item Originalbilder vs. Rausch--Verfälschungen des Originals
\end{itemize} 
\noindent
Die Gesamtanzahl der untersuchten Vergleichspaare beträgt \hbox{135 Paare}. Die folgende Abbildung~\ref{fig:experimental_frr_brushes}
repräsentiert die ermittelt Durchschnittsergebnisse:
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/frr_brushes.png}
	\caption{FRR der \textit{Elementaren Formen} (Eigene Darstellung)}
	\label{fig:experimental_frr_brushes}
\end{figure}
\noindent
Der Abbildung~\ref{fig:experimental_frr_brushes} zufolge ist der \textit{BMB}--Algorithmus mit einer durchschnittlichen Fehlerrate
von $\varnothing FRR = 0,34$ das stabilste Verfahren in diesem Experiment. Dahingegen überzeugt die \textit{Wavelet}--Vorgehensweise
mit einer Durchschnittsfehlerrate von \hbox{$\varnothing FRR = 0,87$} nicht. Sowohl der \textit{DCT}--Ansatz ($\varnothing FRR = 0.45$) als auch das
\textit{RADISH}--Vorgehen ($\varnothing FRR = 0.51$) weisen nur geringfügige Unterschiede in den Ergebnissen auf und belegen somit das Mittelfeld.

\subsubsection{Originalbild vs. Modifikationen (\textit{Komplexe Bilder})}
Das Experiment ist von dem Ablauf bis auf die untersuchte Datenkategorie identisch zu dem Vorherigen. Anstelle der elementaren Formen
wird das Verhalten der Algorithmen jedoch hinsichtlich der Kategorie \textit{Komplexe Bilder} analysiert. Das Bildmaterial generiert 105 unterschiedliche
Vergleichspaare und führt zu dem in Abbildung~\ref{fig:experimental_frr_images} dargestellten Resultat.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/frr_images.png}
	\caption{FRR der \textit{Komplexen Bilder} (Eigene Darstellung)}
	\label{fig:experimental_frr_images}
\end{figure}
\noindent
Durch den Austausch der elementaren Formen gegen komplexere Bilder kann eine Reduzierung der durchschnittlichen Fehlerraten erzielt werden.
Im Ergebnis können für den Testfall \textit{Originalbilder vs. Gamma--Angleichungen des Originals} schlechtere \textit{FRR}--Werte beobachtet
werden, wohingegen sich die restlichen Testfälle verbessern oder ähnliche Ergebnisse wie im vorherigen Experiment liefern.
\\
Die folgenden Tabelle~\ref{tab:experimental_mfrr_images} beinhaltet die Durchschnittsfehlerraten der vier Algorithmen.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|}
			\mytoprule
			\centering\bfseries Algorithmus & \bfseries \textit{FRR}
			\\
			\hline
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			RADISH & 0,26
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			DCT & 0,48
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			Wavelet & 0,79
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			BMB & 0,36
			\\																			
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Durchschnittsfehlerraten (Eigene Darstellung)}
		\label{tab:experimental_mfrr_images}
	\end{center}
\end{table}	

\subsubsection{Erkennungsraten beim Quervergleich (\textit{Komplexe\\Bilder})}
\label{sec:experimental_cc_images}
Im Gegensatz zu den beiden vorherigen Experimenten wird bei diesem Test nicht die \textit{False--Rejection--Rate} als Maß für
die Fehlerrate verwendet, sondern die \textit{False--Acceptance--Rate}. Bei einem Kreuzvergleich mit allem aus der Kategorie
\textit{Komplexe Bilder} stammenden Bildmaterial, ist die Detektierung von als fälschlich ähnlich markierten Bildpaaren das Testziel,
wodurch weitere Rückschlüsse auf die potentielle interne Arbeitsweise der Algorithmen gezogen werden können. Der Inhaltsumfang beträgt
dabei \hbox{8001 verschiedene Vergleichspaare}.
\\
Das Erkennungsverhalten der einzelnen Algorithmen wird für drei Threshold--Stufen (90\%, 80\% und 70\%) protokolliert und führt
zu dem in der Abbildung~\ref{fig:experimental_far_cc} illustrierten Ergebnis.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/far_crosscomparison.png}
	\caption{FAR des Quervergleichs der \textit{Komplexen Bilder} (Eigene Darstellung)}
	\label{fig:experimental_far_cc}
\end{figure}
\noindent
\\
Erwartungsgemäß ist ein paralleler Anstieg der tolerierten Fehler während des Vergleichs von Ähnlichkeiten mit der Verringerung des
genutzten Thresholds zu beobachten. Eine Ausnahme stellt die \textit{Wavelet}--Vorgehensweise dar, die in allen drei Stufen keine
Vergleichspaare fälschlicherweise als ähnlich deklariert.
\\
Besonders die auftretenden Fehlerraten der Verfahren \textit{BMB} und \textit{RADISH} wurden durch die Änderung des Thresholds beeinflusst.

\subsection{Geschwindigkeitsanalysen}
Der Einsatz neuer Verfahrensweisen in etablierte Systemstrukturen führt oftmals zu einem nicht unerheblichen Aufwand für
die beteiligten Stakeholder. Vor der Integration sind somit eingehende Tests notwendig um die Effizienz des neues Ansatzes zu
validieren sowie zu bestätigen.
\\
In dem Fall von \textit{Perceptual Hashing} ist neben der Verifizierung der Fehlerraten ebenfalls die benötigte Zeit beziehungsweise
die Berechnungsgeschwindigkeit der beteiligten Algorithmen eine ausschlaggebende Eigenschaft für deren Verwendung.
\\
Die nachfolgenden Experimente analysieren die Berechnungszeiten und setzen diese in einen direkten Vergleich mit bereits bestehenden
nativen Ansätzen.

\subsubsection{Berechnungszeiten der Algorithmen}
\label{sec:experimental_speed}
Die durchschnittlichen Berechnungszeiten der vier Algorithmen basieren auf einer Vielzahl von Rahmenbedingungen. Am ausschlaggebendsten
ist die Kommunikationsgeschwindigkeit zwischen den verschiedenen Infrastrukturen (zum Beispiel die Geschwindigkeit der Host--Festplatte
oder die Internetgeschwindigkeit), die wiederum, unabhängig von der eigentlichen Berechnungsgeschwindigkeit, als konstante (Lade--)Zeit
in die Gesamtzeit mit eingeht.
\\
Ein zusätzlicher Faktor ist durch die Implementierung (zum Beispiel eine Optimierung für die Verwendung von mehreren CPU--Kernen) der
einzelnen Algorithmen gegeben, die zuzüglich der Parametrisierung einen großen Einfluss auf die Geschwindigkeit während der Berechnung ausübt.
Die eigentliche Kalkulation ist darüber hinaus an die CPU--Geschwindigkeit gebunden.
\\
Die Bestimmung der durchschnittlichen Berechnungszeiten (beinhaltet keine Ladezeiten) der vier betrachteten Algorithmen wird mit Hilfe der
Kategorie \textit{Komplexe Bilder} ausgeführt, wobei nur die drei Gruppen berücksichtigt werden: \textit{Original, Verkleinerungen und Vergrößerungen}.
Zur Sicherstellung, dass die ermittelten Zeiten unverfälscht gemessen werden und somit den Ansprüchen der Wiederholbarkeit genügen,
werden keine weiteren Optimierungsschritte integriert.
\\
Die Berechnungszeiten der vier Verfahren können in der Abbildung~\ref{fig:experimental_speed} abgelesen werden.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/speed.png}
	\caption{Durchschnittliche Berechnungszeiten (Eigene Darstellung)}
	\label{fig:experimental_speed}
\end{figure}
\noindent
Die Berechnungszeiten für jeden Algorithmus steigen erwartungsgemäß mit einer Zunahme an Bildinformationen an. Die Verfahren \textit{BMB} sowie
\textit{RADISH} berechnen den Hashwert durchschnittlich effizienter als die Ansätze \textit{DCT} und \textit{Wavelet}.
Diese Beobachtungen decken sich mit anderen wissenschaftlichen Ausarbeitungen (vgl.~\cite{ZAU10}).
\\
Besonders die erhöhte Berechnungszeit des \textit{Wavelet}--Algorithmus ist bei dem verkleinerten Bildmaterial hervorzuheben.
\\[1em]
Mit Hilfe der vorangehenden Abbildung~\ref{fig:experimental_speed} können die nachstehenden linearen Trendlinien für die Algorithmen
\textit{RADISH}~(\ref{eq:experimental_speed_radish_trend}), \textit{DCT}~(\ref{eq:experimental_speed_dct_trend}),
\textit{Wavelet}~(\ref{eq:experimental_speed_wavelet_trend}) und \textit{BMB}~(\ref{eq:experimental_speed_bmb_trend}) ermittelt werden.
\\
\begin{minipage}[H]{0.49\linewidth}
	\begin{equation}
		\label{eq:experimental_speed_radish_trend}
		y = 0,1286x - 0,1493
	\end{equation}
	\vspace{-3em}
	\begin{equation}
		\label{eq:experimental_speed_dct_trend}
		y = 0,2635x - 0,3037
	\end{equation}	
\end{minipage}
\begin{minipage}[H]{0.49\linewidth}
	\begin{equation}
		\label{eq:experimental_speed_wavelet_trend}
		y = 0,154x + 0,0543
	\end{equation}
	\vspace{-3em}
	\begin{equation}
		\label{eq:experimental_speed_bmb_trend}
		y = 0,045x - 0,0517
	\end{equation}
\end{minipage}

\subsubsection{Kreuzkorrelation mit vollständigem Informationsraum}
\label{sec:experimental_speed_cc}
Ohne einen konkreten zeitlichen Bezugspunkt besteht keine Möglichkeit qualitative Aussagen über die im vorherigen Test ermittelten
Durchschnittsgeschwindigkeiten der einzelnen Algorithmen zu treffen und somit die potentielle Zeitabnahme zu unterstreichen.
\\
Die Definition einer zeitlichen Referenzachse erfolgt mit Hilfe des aus der Signalanalyse stammende Verfahren \textit{Kreuzkorrelation},
das ein Maß der Ähnlichkeit von zwei unterschiedlichen Signalen beschreibt (\cite{MAR95}). In dem vorliegenden Experiment werden unterdessen
diskrete Werte in Form von Bildinformationen adressiert.
\\[1em]
Die zeitliche Analyse des nativen Ansatzes wird mit den drei Kategorien \textit{Einfache Farben}, \textit{Elementare Formen} und
\textit{Komplexe Bilder} ausgeführt. Für eine verbesserte Protokollierung der zeitlichen Entwicklung hinsichtlich
der ansteigenden Komplexität des verwendeten Bildmaterials, erfolgt eine Skalierung der Eingabebilder in vier verschiedene
Dimensionen: \textit{100x100px} (1), \textit{200x200px} (2), \textit{300x300px} (3) und \textit{600x600px} (4).
\\
Zusätzlich werden die Farbbilder in Graustufenbilder umgewandelt, sodass die Ausgangssituation für die \textit{Kreuzkorrelation}
grundlegenden ähnlich zu den anderen Algorithmen ist. Ansonsten werden keine weiteren Optimierungen vorgenommen.
\\[1em]
Jedes Kombinationspaar aus Kategorie und Dimension ergibt dabei zehn Zeitwerte, sodass insgesamt 120 verschiedene Messwerte
für die Berechnungszeit mittels \textit{Kreuzkorrelation} vorliegen. Die während der Berechnung erzielten Erkennungsraten
sind für das Experiment uninteressant und somit nicht weiter aufgeführt.
\\
Die ermittelten Durchschnittszeiten können der nachstehenden Tabelle~\ref{tab:experimental_speed_cc} entnommen werden.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|c|c|c|}
			\mytoprule
			\centering\bfseries Kategorie & \bfseries(1) & \bfseries(2) & \bfseries(3) & \bfseries(4)
			\\
			\hline
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			\textit{Einfache Farben} & 1,58s & 26,13s & 135,09s & 2258,78s
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			\textit{Elementare Formen} & 1,58s & 26,36s & 135,24s & 2259,02s
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			\textit{Komplexe Bilder} & 1,63s & 26,65s & 136,08s & 2260,31s
			\\	
			\hline
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			\textit{Gesamt} & 1,59s & 26,38s & 135,47s & 2259,37s
			\\																				
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Durchschnittszeiten der \textit{Kreuzkorrelation} (Eigene Darstellung)}
		\label{tab:experimental_speed_cc}
	\end{center}
\end{table}	
\noindent
Aus der Tabelle~\ref{tab:experimental_speed_cc} kann dementsprechend die folgende lineare Trendlinie~(\ref{eq:experimental_speed_cc_trend}) errechnet werden:
\begin{equation}
	\label{eq:experimental_speed_cc_trend}
	y = 688,32x - 1114,9
\end{equation}