%#####################################################################################################################
% Datei	: Experimental.tex
% Autor	: Byron Worms
%#####################################################################################################################
%---------------------------------------------------------------------------------------------------------------------
% Experimental Investigation
%---------------------------------------------------------------------------------------------------------------------
\section{Experimentelle Untersuchungen}
\label{sec:experimental}
Die theoretische Definition und Beschreibung der einzelnen Algorithmen bieten keine Möglichkeit Rückschlüsse über die generelle
Einsetzbarkeit in Abhängigkeit des verwendeten Bildmaterials zu ziehen. Aufgrund der hohen Komplexität und Varianz in
den bildlichen Strukturen, können keine allgemeingültigen Aussagen über den Zusammenhang zwischen fehlerhaften Ergebnissen
der Verfahren und dem strukturellen Aufbau der Bilder getroffen werden.
\\
Mit Hilfe der in Sektion~\ref{sec:solution} (\textit{Lösungsansatz}) wohldefinierten Kategorien an variierenden
Bildmaterials, in Bezug auf Komplexität sowie Strukturaufbau, soll eine potentielle Korrelation zwischen den strukturellen
Gegebenheiten und den grundlegenden Funktionsweisen der Algorithmen untersucht werden.
\\
Bereits in der Wissenschaft bekannte Fehleranfälligkeiten der genutzten Strategien werden dabei als solche markiert und nicht
näher erläutert.
\\[1em]
Die nachfolgende Auflistung beinhaltet eine Übersicht der durchgeführten und in Kategorien gruppierten Experimente:
\begin{enumerate}[noitemsep]
	\item \boldtext{Fundamentale Funktionalitätstests}
		\begin{itemize}[noitemsep]
			\item Erkennungsraten bei Identitätstests
			\item Erkennungsraten der \textit{Einfachen Farben}
		\end{itemize}
		
	\item \boldtext{Vertiefte Funktionalitätsanalysen}
		\begin{itemize}[noitemsep]
			\item Originalbild vs. Modifikationen (\textit{Elementare Formen})
			\item Originalbild vs. Modifikationen (\textit{Komplexe Bilder})
			\item Erkennungsraten beim Quervergleich \textit{Komplexe Bilder}
		\end{itemize}		
		
	\item \boldtext{Geschwindigkeitsanalysen}
		\begin{itemize}[noitemsep]
			\item Berechnungszeiten der Algorithmen
			\item tbd (Hash vs Ganzbild)
		\end{itemize}
\end{enumerate}
\noindent
TO DO: Fehlerraten oder so erwähnen (JEWEILS GEMESSENDE DATEN)\\
\boldtext{Testsystem und Parametrisierung}\\
Für die Gewährleistung, dass die einzelnen Experimente in weitestgehend system-- sowie hardwareunabhängigen Ergebnissen resultieren,
geschieht deren Durchführung ausschließlich auf dem nachstehenden System:
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|l|}
			\mytoprule
			%---------------------------------------------------------------------------------------------------------------------	
			Betriebssystem & Windows 8.1, x64
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			Prozessor & AMD x6 1055t (~3.3GHz)
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			RAM & 8GB DDR3
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			Festplatte & SamsungSSD 850 EVO 512GB
			\\																			
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Testsystem (eigene Darstellung)}
		\label{tab:experimental_testsystem}
	\end{center}
\end{table}	
\noindent
Die Parametrisierung der unterschiedlichen Algorithmen erfolgt nach den in der Bibliothek \textit{pHash} angegebenen Standardwerte:
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|l|}
			\mytoprule
			\centering\bfseries Algorithmus & \bfseries Parameter(--typ)
			\\
			\hline
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			RADISH & Gamma: 1 \\
			& Sigma: 2 \\
			& \#Winkel: 180
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			DCT & --
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			Wavelet & Alpha: 2 \\
			& Level: 1
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			BMB & Methode: 1
			\\																			
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Parametrisierung der Algorithmen (nach~\cite{PHASH})}
		\label{tab:experimental_params}
	\end{center}
\end{table}	
\noindent

\subsection{Fundamentale Funktionalitätstests}
Der Bereich der konstitutiven Funktionalitätstests dient der Protokollierung von grundlegenden (und vorausgesetzten) internen
Arbeitsweisen der zu betrachtenden Algorithmen.

\subsubsection{Erkennungsraten bei Identitätstests}
Die Durchführung des Identitätstests dient als erforderliche Grundlage für alle nachfolgenden aufgestellten Testfälle und wird
daher für alle vier Algorithmen realisiert. Während der Ausführung werden die Bilder aus den Kategorien \textit{Elementare Formen}
sowie \textit{Komplexe Bilder} gegen die eigene Identität verglichen und die eventuell entstehenden Fehler protokolliert.
\\
Das Experiment umfasste insgesamt 288 unterschiedliche Bilddaten und führte zu dem nachstehenden Ergebnis:
\begin{equation*}
	FRR = 0
\end{equation*}
\noindent
Daraus lässt sich schlussfolgern, dass die vier Ansätze für die Berechnung von Perceptual Hashes mit einer hohen Wahrscheinlichkeit
eine deterministische Vorgehensweise inhärieren. Für eine 100\%e Sicherheit ist hingegen ein formaler Beweis notwendig, der nicht im Rahmen
des vorliegenden Papers abgedeckt wird.

\subsubsection{Erkennungsraten der \textit{Einfachen Farben}}
Das Experiment hat einen Quervergleich aller 9 einfarbigen Bilder der Kategorie \textit{Einfache Farben} mit allen vier Verfahren durchgeführt.
Die entstehenden Resultate basieren dabei auf der Natur der internen Funktionsweise der Vergleichsalgorithmen für die Hashdaten
(detaillierte Erläuterung kann TODO TODO TODO).
\\
Der Test beinhaltete 45 Vergleichsmöglichkeiten und generierte das folgende Ergebnis:
\begin{equation*}
	FRR = 1, FAR = 1
\end{equation*}

\subsection{Vertiefte Funktionalitätsanalysen}
Mit Hilfe der nachstehenden Experimente werden Untersuchungen bezüglich sowohl der Erkennungsstabilität bei Modifikationen des
Originalbildmaterials als auch der Detektierung von fälschlich als ähnlich markierten Vergleichspaaren dargelegt. 

\subsubsection{Originalbild vs. Modifikationen (\textit{Elementare Formen}}
Dieser Test analysiert die Robustheit der Algorithmen hinsichtlich der Bilder sowie deren Modifikationen aus der Kategorie
\textit{Elementare Formen}.
Durchführung des Tests erfolgte wie nachstehend:
\begin{itemize}[noitemsep]
	\item Originalbilder vs. Verkleinerungen des Originals
	\item Originalbilder vs. Vergrößerungen des Originals
	\item Originalbilder vs. Rotationen des Originals
	\item Originalbilder vs. Gamma--Angleichungen des Originals
	\item Originalbilder vs. Noise--Verfälschungen des Originals
\end{itemize} 
\noindent
Die Gesamtanzahl der untersuchten Vergleichspaare betrug \hbox{135 Paare}. Die folgenden Abbildung~\ref{fig:experimental_frr_brushes}
repräsentiert die ermittelt Durchschnittsergebnisse (TODO: ANHANG FÜR TABELLEN; TRENNUNG DER GRUPPE!).
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/frr_brushes.png}
	\caption{FRR der \textit{Elementaren Formen} (Eigene Darstellung)}
	\label{fig:experimental_frr_brushes}
\end{figure}
\noindent
Der Abbildung~\ref{fig:experimental_frr_brushes} nach zufolge, ist der \textit{BMB}--Algorithmus mit einer durchschnittlichen Fehlerrate
von $\varnothing FRR = 0,34$ das stabilste Verfahren in diesem Experiment. Dahingegen verhält sich die \textit{Wavelet}--Vorgehensweise
mit einer Durchschnittsfehlerrate von $\varnothing FRR = 0,87$ am negativsten. Sowohl der \textit{DCT}--Ansatz ($\varnothing FRR = 0.45$) als auch das
\textit{RADISH}--Vorgehen ($\varnothing FRR = 0.51$) weisen nur geringfügige Unterschiede in den Ergebnissen auf und belegen somit das Mittelfeld.

\subsubsection{Originalbild vs. Modifikationen (\textit{Komplexe Bilder}}
Das Experiment ist von dem Ablauf bis auf die untersuchte Datenkategorie identisch zu dem Vorherigen. Anstelle der elementaren Formen
wird das Verhalten der Algorithmen hinsichtlich der Kategorie \textit{Komplexe Bilder} analysiert. Das Bildmaterial generierte 105 unterschiedliche
Vergleichspaare und führte zu dem in Abbildung~\ref{fig:experimental_frr_images} dargestellten Resultat.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/frr_images.png}
	\caption{FRR der \textit{Komplexen Bilder} (Eigene Darstellung)}
	\label{fig:experimental_frr_images}
\end{figure}
\noindent
Durch den Austausch der elementaren Formen gegen komplexere Bilder konnte eine Reduzierung der durchschnittlichen Fehlerraten erzielt werden.
Im Ergebnis konnten für den Testfall \textit{Originalbilder vs. Gamma--Angleichungen des Originals} schlechtere \textit{FRR}--Werte beobachtet
werden, wohingegen sich die restlichen Testfälle verbesserten oder ähnliche Ergebnisse wie im vorherigen Experiment lieferten.
\\
Die folgenden Tabelle~\ref{tab:experimental_mfrr_images} beinhaltet die Durchschnittsfehlerraten der vier Algorithmen.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|}
			\mytoprule
			\centering\bfseries Algorithmus & \bfseries \textit{FRR}
			\\
			\hline
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			RADISH & 0,26
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			DCT & 0,48
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			Wavelet & 0,79
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			BMB & 0,36
			\\																			
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Durchschnittsfehlerraten (eigene Darstellung)}
		\label{tab:experimental_mfrr_images}
	\end{center}
\end{table}	

\subsubsection{Erkennungsraten beim Quervergleich \textit{Komplexe Bilder}}
Im Gegensatz zu den beiden vorherigen[SYN] Experimenten wird bei diesem Test nicht die \textit{False--Rejection--Rate} als Maß für
die Fehlerrate verwendet, sondern die \textit{False--Acceptance--Rate}. Bei einem Kreuzvergleich mit allem aus der Kategorie
\textit{Komplexe Bilder} stammenden Bildmaterials ist die Detektierung von als fälschlich ähnlich markierten Bildpaaren das Testziel,
wodurch weitere Rückschlüsse auf die potentielle interne Arbeitsweise der Algorithmen gezogen werden können. Der Inhaltsumfang betrug
dabei \hbox{8001 verschiedene Vergleichspaare}.
\\
Das Erkennungsverhalten der einzelnen Algorithmen wurde für drei Threshold--Stufen (90\%, 80\% und 70\%) protokolliert und führte
zu dem in der Abbildung~\ref{fig:experimental_far_cc} illustrierte Ergebnis.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/far_crosscomparison.png}
	\caption{FAR des Quervergleichs der \textit{Komplexen Bilder} (Eigene Darstellung)}
	\label{fig:experimental_far_cc}
\end{figure}
\noindent
Erwartungsgemäß ist ein paralleler Einsteig der tolerierten Fehler während des Vergleichs von Ähnlichkeiten mit der Verringerung des
genutzten Thresholds zu beobachten. Eine Ausnahme stellt die \textit{Wavelet}--Vorgehensweise dar, die in allen drei Stufen keine
Vergleichspaare fälschlicherweise als ähnlich deklarierte.
\\
Besonders die auftretenden Fehlerraten der Verfahren \textit{BMB} und \textit{RADISH} wurden durch die Änderung des Thresholds beeinflusst.

\subsection{Geschwindigkeitsanalysen}
\subsubsection{Berechnungszeiten der Algorithmen}
\subsubsection{tbd}