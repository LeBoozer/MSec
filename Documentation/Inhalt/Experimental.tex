%#####################################################################################################################
% Datei	: Experimental.tex
% Autor	: Byron Worms
%#####################################################################################################################
%---------------------------------------------------------------------------------------------------------------------
% Experimental Investigation
%---------------------------------------------------------------------------------------------------------------------
\section{Experimentelle Untersuchungen}
\label{sec:experimental}
Die theoretische Definition und Beschreibung der einzelnen Algorithmen bieten keine Möglichkeiten Rückschlüsse über die generelle
Einsetzbarkeit in Abhängigkeit des verwendeten Bildmaterials zu ziehen. Aufgrund der hohen Komplexität und Varianz in
den bildlichen Strukturen, können keine allgemeingültigen Aussagen über den Zusammenhang zwischen fehlerhaften Ergebnissen
der Verfahren und dem strukturellen Aufbau der Bilder getroffen werden.
\\
Mit Hilfe der in Abschnitt~\ref{sec:solution} (\textit{Lösungsansatz}) wohldefinierten Kategorien variierenden
Bildmaterials, in Bezug auf Komplexität sowie Strukturaufbau, soll neben der Protokollierung der Stärken und Schwächen der
Algorithmen eine potentielle Korrelation zwischen den strukturellen Gegebenheiten und den grundlegenden Funktionsweisen der
Ansätze untersucht werden.
\\[1em]
Die nachfolgende Auflistung beinhaltet eine Übersicht der durchgeführten und in Kategorien gruppierten Experimente:
\begin{enumerate}[noitemsep]
	\item \boldtext{Fundamentale Funktionalitätstests}
		\begin{itemize}[noitemsep]
			\item Erkennungsraten bei Identitätstests
			\item Erkennungsraten der \textit{Einfachen Farben}
		\end{itemize}
		
	\item \boldtext{Vertiefte Funktionalitätsanalysen}
		\begin{itemize}[noitemsep]
			\item Originalbild vs. Modifikationen (\textit{Elementare Formen})
			\item Originalbild vs. Modifikationen (\textit{Komplexe Bilder})
			\item Erkennungsraten beim Quervergleich \textit{Komplexe Bilder}
		\end{itemize}		
		
	\item \boldtext{Geschwindigkeitsanalysen}
		\begin{itemize}[noitemsep]
			\item Berechnungszeiten der Algorithmen
			\item tbd (Hash vs Ganzbild)
		\end{itemize}
\end{enumerate}
\noindent
TO DO: Fehlerraten oder so erwähnen (JEWEILS GEMESSENDE DATEN)\\
\boldtext{Testsystem und Parametrisierung}\\
Für die Gewährleistung, dass die einzelnen Experimente in weitestgehend system-- sowie hardwareunabhängigen Ergebnissen resultieren,
geschieht deren Durchführung ausschließlich auf dem in Tabelle~\ref{tab:experimental_testsystem} beschriebenen System:
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|l|}
			\mytoprule
			%---------------------------------------------------------------------------------------------------------------------	
			Betriebssystem & Windows 8.1, x64
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			Prozessor & AMD x6 1055t (~3.3GHz)
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			RAM & 8GB DDR3
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			Festplatte & SamsungSSD 850 EVO 512GB
			\\																			
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Testsystem (eigene Darstellung)}
		\label{tab:experimental_testsystem}
	\end{center}
\end{table}	
\noindent
Die Parametrisierung der unterschiedlichen Algorithmen erfolgt nach den in der Bibliothek \textit{pHash} angegebenen Standardwerten:
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|l|}
			\mytoprule
			\centering\bfseries Algorithmus & \bfseries Parameter(--typ)
			\\
			\hline
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			RADISH & Gamma: 1 \\
			& Sigma: 2 \\
			& \#Winkel: 180
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			DCT & --
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			Wavelet & Alpha: 2 \\
			& Level: 1
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			BMB & Methode: 1
			\\																			
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Parametrisierung der Algorithmen (nach~\cite{PHASH})}
		\label{tab:experimental_params}
	\end{center}
\end{table}	
\noindent

\subsection{Fundamentale Funktionalitätstests}
Der Bereich der konstitutiven Funktionalitätstests dient der Protokollierung von grundlegenden (und vorausgesetzten) internen
Arbeitsweisen der zu betrachtenden Algorithmen.

\subsubsection{Erkennungsraten bei Identitätstests}
\label{sec:experimental_selftests}
Die Durchführung des Identitätstests dient als erforderliche Grundlage für alle nachfolgenden aufgestellten Testfälle und wird
daher für alle vier Algorithmen realisiert. Während der Ausführung werden die Bilder aus den Kategorien \textit{Elementare Formen}
sowie \textit{Komplexe Bilder} gegen die eigene Identität verglichen und die eventuell entstehenden Fehler protokolliert.
\\
Das Experiment umfasst insgesamt 288 unterschiedliche Bilddaten und führte zu dem nachstehenden Ergebnis:
\begin{equation*}
	FRR = 0
\end{equation*}
\noindent
Daraus lässt sich schlussfolgern, dass die vier Ansätze für die Berechnung von Perceptual Hashes mit einer hohen Wahrscheinlichkeit
eine deterministische Vorgehensweise inhärieren. Für eine absolute Sicherheit ist hingegen ein formaler Beweis notwendig, der aufgrund der Komplexität
nicht im Rahmen des vorliegenden Papers abgedeckt werden kann.

\subsubsection{Erkennungsraten der \textit{Einfachen Farben}}
Das Experiment hat einen Quervergleich aller neun einfarbigen Bilder der Kategorie \textit{Einfache Farben} mit allen vier Verfahren durchgeführt.
Die entstehenden Resultate basieren dabei auf der Natur der internen Funktionsweise der Vergleichsalgorithmen für die Hashdaten
(eine detaillierte Erläuterung erfolgt in Abschnitt~\ref{sec:results} (\textit{Testergebnisse})).
\\
Der Test beinhaltete 45 Vergleichsmöglichkeiten und generierte das folgende Ergebnis:
\begin{equation*}
	FRR = 1, FAR = 1
\end{equation*}

\subsection{Vertiefte Funktionalitätsanalysen}
Mit Hilfe der nachstehenden Experimente werden Untersuchungen bezüglich der Erkennungsstabilität bei Modifikationen des
Originalbildmaterials und der Detektierung von fälschlich als ähnlich markierten Vergleichspaaren dargelegt. 

\subsubsection{Originalbild vs. Modifikationen (\textit{Elementare Formen})}
\label{sec:experimental_origvsmod_brushes}
Dieser Test analysiert die Robustheit der Algorithmen hinsichtlich der Bilder sowie deren Modifikationen aus der Kategorie
\textit{Elementare Formen}.
Die Durchführung des Tests erfolgte wie nachstehend:
\begin{itemize}[noitemsep]
	\item Originalbilder vs. Verkleinerungen des Originals
	\item Originalbilder vs. Vergrößerungen des Originals
	\item Originalbilder vs. Rotationen des Originals
	\item Originalbilder vs. Gamma--Angleichungen des Originals
	\item Originalbilder vs. Noise--Verfälschungen des Originals
\end{itemize} 
\noindent
Die Gesamtanzahl der untersuchten Vergleichspaare betrug \hbox{135 Paare}. Die folgende Abbildung~\ref{fig:experimental_frr_brushes}
repräsentiert die ermittelt Durchschnittsergebnisse (TODO: ANHANG FÜR TABELLEN; TRENNUNG DER GRUPPE!).
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/frr_brushes.png}
	\caption{FRR der \textit{Elementaren Formen} (Eigene Darstellung)}
	\label{fig:experimental_frr_brushes}
\end{figure}
\noindent
Der Abbildung~\ref{fig:experimental_frr_brushes} zufolge ist der \textit{BMB}--Algorithmus mit einer durchschnittlichen Fehlerrate
von $\varnothing FRR = 0,34$ das stabilste Verfahren in diesem Experiment. Dahingegen verhält sich die \textit{Wavelet}--Vorgehensweise
mit einer Durchschnittsfehlerrate von $\varnothing FRR = 0,87$ am negativsten. Sowohl der \textit{DCT}--Ansatz ($\varnothing FRR = 0.45$) als auch das
\textit{RADISH}--Vorgehen ($\varnothing FRR = 0.51$) weisen nur geringfügige Unterschiede in den Ergebnissen auf und belegen somit das Mittelfeld.

\subsubsection{Originalbild vs. Modifikationen (\textit{Komplexe Bilder})}
Das Experiment ist von dem Ablauf bis auf die untersuchte Datenkategorie identisch zu dem Vorherigen. Anstelle der elementaren Formen
wird das Verhalten der Algorithmen jedoch hinsichtlich der Kategorie \textit{Komplexe Bilder} analysiert. Das Bildmaterial generierte 105 unterschiedliche
Vergleichspaare und führte zu dem in Abbildung~\ref{fig:experimental_frr_images} dargestellten Resultat.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/frr_images.png}
	\caption{FRR der \textit{Komplexen Bilder} (Eigene Darstellung)}
	\label{fig:experimental_frr_images}
\end{figure}
\noindent
Durch den Austausch der elementaren Formen gegen komplexere Bilder konnte eine Reduzierung der durchschnittlichen Fehlerraten erzielt werden.
Im Ergebnis konnten für den Testfall \textit{Originalbilder vs. Gamma--Angleichungen des Originals} schlechtere \textit{FRR}--Werte beobachtet
werden, wohingegen sich die restlichen Testfälle verbesserten oder ähnliche Ergebnisse wie im vorherigen Experiment lieferten.
\\
Die folgenden Tabelle~\ref{tab:experimental_mfrr_images} beinhaltet die Durchschnittsfehlerraten der vier Algorithmen.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|}
			\mytoprule
			\centering\bfseries Algorithmus & \bfseries \textit{FRR}
			\\
			\hline
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			RADISH & 0,26
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			DCT & 0,48
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			Wavelet & 0,79
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			BMB & 0,36
			\\																			
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Durchschnittsfehlerraten (eigene Darstellung)}
		\label{tab:experimental_mfrr_images}
	\end{center}
\end{table}	

\subsubsection{Erkennungsraten beim Quervergleich (\textit{Komplexe Bilder})}
\label{sec:experimental_cc_images}
Im Gegensatz zu den beiden vorherigen[SYN] Experimenten wird bei diesem Test nicht die \textit{False--Rejection--Rate} als Maß für
die Fehlerrate verwendet, sondern die \textit{False--Acceptance--Rate}. Bei einem Kreuzvergleich mit allem aus der Kategorie
\textit{Komplexe Bilder} stammenden Bildmaterial, ist die Detektierung von als fälschlich ähnlich markierten Bildpaaren das Testziel,
wodurch weitere Rückschlüsse auf die potentielle interne Arbeitsweise der Algorithmen gezogen werden können. Der Inhaltsumfang betrug
dabei \hbox{8001 verschiedene Vergleichspaare}.
\\
Das Erkennungsverhalten der einzelnen Algorithmen wurde für drei Threshold--Stufen (90\%, 80\% und 70\%) protokolliert und führte
zu dem in der Abbildung~\ref{fig:experimental_far_cc} illustrierten Ergebnis.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/far_crosscomparison.png}
	\caption{FAR des Quervergleichs der \textit{Komplexen Bilder} (Eigene Darstellung)}
	\label{fig:experimental_far_cc}
\end{figure}
\noindent
Erwartungsgemäß ist ein paralleler Anstieg der tolerierten Fehler während des Vergleichs von Ähnlichkeiten mit der Verringerung des
genutzten Thresholds zu beobachten. Eine Ausnahme stellt die \textit{Wavelet}--Vorgehensweise dar, die in allen drei Stufen keine
Vergleichspaare fälschlicherweise als ähnlich deklarierte.
\\
Besonders die auftretenden Fehlerraten der Verfahren \textit{BMB} und \textit{RADISH} wurden durch die Änderung des Thresholds beeinflusst.

\subsection{Geschwindigkeitsanalysen}
Der Einsatz neuer Verfahrensweisen in etablierte Systemstrukturen führt oftmals zu einem nicht unerheblichen Aufwand für
die beteiligten Stakeholder. Vor der Integration sind somit eingehende Tests notwendig um die Effizienz des neues Ansatzes zu
validieren sowie zu bestätigen.
\\
In dem Fall von \textit{Perceptual Hashing} ist neben der Verifizierung der Fehlerraten ebenfalls die benötigte Zeit beziehungsweise
die Berechnungsgeschwindigkeit der beteiligten Algorithmen eine ausschlaggebende Eigenschaft für dessen Verwendung.
\\
Die nachfolgenden Experimente analysieren die Berechnungszeiten und setzen diese in einen direkten Vergleich mit bereits bestehenden
Ansätzen.

\subsubsection{Berechnungszeiten der Algorithmen}
\label{sec:experimental_speed}
Die durchschnittlichen Berechnungszeiten der vier Algorithmen basieren auf einer Vielzahl von Rahmenbedingungen. Am ausschlaggebendsten
ist die Kommunikationsgeschwindigkeit zwischen den verschiedenen Infrastrukturen (zum Beispiel die Geschwindigkeit der Host--Festplatte
oder die Internetgeschwindigkeit), die wiederum, unabhängig von der eigentlichen
Berechnungsgeschwindigkeit, als konstante (Lade--)Zeit in die Gesamtzeit mit eingeht.
\\
Ein zusätzlicher Faktor ist durch die Implementierung (zum Beispiel eine Optimierung für die Verwendung von mehreren CPU--Kernen) der
einzelnen Algorithmen gegeben, die zuzüglich der Parametrisierung einen großen Einfluss auf die Geschwindigkeit während der Berechnung ausübt.
Die eigentliche Berechnung[SYN] ist zusätzlich[SYN] an die CPU--Geschwindigkeit gebunden.
\\
Die Bestimmung der durchschnittlichen Berechnungszeiten (beinhalten keine Ladezeiten) der vier betrachteten Algorithmen wurde mit Hilfe der
Kategorie \textit{Komplexe Bilder} ausgeführt, wobei nur die drei Gruppen berücksichtigt wurden: \textit{Original, Verkleinerungen und Vergrößerungen}.
TODO: AUSBLEIB VON OPTIMIERUNGEN; JEDES MAL WIEDER GELADEN UND BERECHNET; SYSTEM WIE OBEN GENUTZT; 6 KERNE!\\
Die Berechnungszeiten für die vier Verfahren können in der Abbildung~\ref{fig:experimental_speed} abgelesen werden.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/speed.png}
	\caption{Durchschnittliche Berechnungszeiten (Eigene Darstellung)}
	\label{fig:experimental_speed}
\end{figure}
\noindent
Die Berechnungszeiten für jeden Algorithmus steigen erwartungsgemäß mit einer Zunahme an Bildinformationen an. Die Verfahren \textit{BMB} sowie
\textit{RADISH} berechnen den Hashwert durchschnittlich am effizientesten, wohingegen die Ansätze \textit{DCT} und \textit{Wavelet} zu
den langsameren Verfahren zählen. Die Beobachtungen decken sich mit~\cite{ZAU10}.
\\
Besonders die erhöhte Berechnungszeit des \textit{Wavelet}--Algorithmus ist bei dem verkleinerten Bildmaterial hervorzuheben.  

\subsubsection{tbd}