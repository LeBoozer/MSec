%#####################################################################################################################
% Datei	: Results.tex
% Autor	: Byron Worms
%#####################################################################################################################
%---------------------------------------------------------------------------------------------------------------------
% Test results
%---------------------------------------------------------------------------------------------------------------------
\section{Testergebnisse}
\label{sec:results}
Nachfolgend werden die Resultate sowie Beobachtungen der durchgeführten Experimente analysiert und mögliche Korrelationen
zwischen den Funktionsweisen der vier eingesetzten Algorithmen und dem verwendeten Bildmaterials aufgezeigt.
\\
Aus der Wissenschaft stammende Fehleranfälligkeiten in der zugrundeliegenden Theorie der einzelnen Verfahren werden
dabei als solche markiert und nicht eingehender erläutert.

\subsection{Fundamentale Funktionalitätstests}
Die Kategorie der fundamentalen Funktionalitätsexperimente umfasst zwei unterschiedlich definierte Testanwendungen.
\\
Die im Abschnitt~\ref{sec:experimental_selftests} (\textit{Erkennungsraten bei Identitätstests}) erzielten Erkenntnisse
des Testfalls erfordern hierbei keine weiteren Diskussion oder Erläuterung.

\subsubsection{Erkennungsraten der \textit{Einfachen Farben}}
In diesem Test ist es keinem Algorithmus möglich gewesen, die bestehenden Ähnlichkeiten zwischen den einzelnen Bildern
richtig zu detektieren. Die fehlenden Strukturinformationen innerhalb des Bildmaterials führten dazu, dass in einem
bestimmten Bearbeitungsschritt der verschiedenen Verfahren ein ähnliches Zwischenergebnis errechnet wurde, sodass
schlussendlich ein identischer Hashwert entstand:
\begin{description}[noitemsep]
	\item[\normalfont RADISH] (Hash: 0) \hfill \\
		Die \textit{Radon--Projektion} liefert für verschiedene einfarbige Graustufenbilder das gleiche Resultat.
	\item[\normalfont DCT] (Hash: 0) \hfill \\
		Die Bildzerlegung in dessen Spektralkomponenten ist für einfarbige Graustufenbilder identisch.
	\item[\normalfont Wavelet] (Hash: 0) \hfill \\
		Fehlende strukturelle Informationen erzeugen ein identisches Ergebnis während der Kantenerkennung.	
	\item[\normalfont BMB] (Hash: 1) \hfill \\
		Der Durchschnitt aller Gitterzellen des uniformen Gitters ist identisch zu den einzelnen Werten der Gitterzellen. 
\end{description}
\noindent
Basierend auf der internen Funktionsweise der eingesetzten Algorithmen für den Hashwertvergleich, ist entweder die \textit{FRR}
oder die \textit{FAR} maximal. Bei identischen Hashwerten liefert die \textit{Hamming Distanz} immer einen Wert von 0
und trägt somit zu der \textit{FAR} bei, während die \textit{Kreuzkorrelation} bei gleichen Hashwerten stets in einem
Wert von 1 resultiert und dadurch die \textit{FRR} steigert.

\subsection{Vertiefte Funktionalitätsanalysen}
Die Kategorie der vertieften Funktionalitätsuntersuchungen umfasst drei unterschiedliche Experimente. Die ersten beiden Tests
analysieren das Verhalten der \textit{FRR} bei der Anwendung von Modifikationen auf das Originalbild, wohingegen der dritte
Testfalls die \textit{FAR} während dem Vergleich von nicht ähnlichen Bildmaterials untersucht.

\subsubsection{Originalbild vs. Modifikationen (\textit{Elementare Formen})}
Während der Durchführung des Experiments wurden die Originalbilder aus der Kategorie \textit{Elementare Formen} gegen deren
modifizierten Versionen verglichen. Ziel der Testanwendung war eine vertiefte Analyse der Algorithmus abhängigen Erkennungsqualitäten
bei strukturell ähnlichem Bildmaterial.
\\[1em]
Ähnlich wie bei den einfachen Farben zuvor, beeinflusst der strukturell einfach aufgebaute Inhalt der Bilder auch hier negativ die
im Abschnitt~\ref{sec:experimental_origvsmod_brushes} protokollierten Ergebnisse. Bereits kleinere Änderungen an dem originalen
Bildmaterial führen zu einer vollkommenen differierenden Modifikation der binären Darstellungsweise, sodass die Algorithmen 
starke Abweichungen während der Bestimmung des Ähnlichkeitsmaßes aufweisen.
\\
Ein Beispiel ist anhand des \textit{Wavelet}--Algorithmus durch die folgende Abbildung~\ref{fig:results_origvsmod_brushes_wavelet} gegeben.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/Wavelet_ResizedDown_Brushes.png}
	\caption{TBD (Eigene Darstellung)}
	\label{fig:results_origvsmod_brushes_wavelet}
\end{figure}
\noindent
Die Verringerung der Auflösung führt innerhalb des Vorbearbeitungsschrittes \textit{Histogramm basierter Ausgleich} zu einem 
vollständig unterschiedlichen Erscheinungsbild, wodurch die Kantenerkennung erheblich mehr Kanten detektiert, als in dem ursprünglichen
Bildmaterial.
\\[1em]
Die häufig angewandte Modifikation \textit{Rotationsänderungen} ist für alle vier Algorithmen ein bestehender Problemfall. Rotationen
sind oftmals für den menschlichen Sehsinn leicht zu detektieren, wohingegen eine maschinelle Erkennung durch die extreme Differenz der
binären Repräsentation eine große Herausforderung darstellt. Der Erkenntnisgewinn spiegelt sich auch in anderen wissenschaftlichen 
Ergebnissen wieder (vgl.~\cite{ZAU10}).

\subsubsection{Originalbild vs. Modifikationen (\textit{Komplexe Bilder})}
Ein Wechsel des Bildmaterials von den elementaren Formen auf die Kategorie \textit{Komplexe Bilder} verbessert allgemein
die entstehende Fehlerrate der verschiedenen Algorithmen während der Bestimmung der Ähnlichkeitsmaße.
\\
Durch den Einsatz von komplexen strukturellen Bildinformationen, weisen Modifikationen einen geringfügigeren Einfluss auf den
eigentlichen Bildinhalt auf. Als Beispiel sei die folgenden Abbildung~\ref{fig:results_origvsmod_images_wavelet} des
\textit{Wavelet}--Algorithmus gegeben.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/Wavelet_ResizedDown_Images.png}
	\caption{TBD (Eigene Darstellung)}
	\label{fig:results_origvsmod_images_wavelet}
\end{figure}
\noindent
Voraussetzung für die minimalere Einflussnahme ist, dass die angewandten Veränderungen eine bestimmte Magnitude nicht
überschreiten. Das Ausmaß bei Überschreitung der gewählten Intensität ist beispielsweise durch den Testfall \textit{Originalbilder vs.
Gamma--Angleichungen des Originals} gegeben, bei dem eine Verschlechterung der Zuordnungsrate für die vier Algorithmen beobachtet wurde.
\\
Rotationsmodifikationen führen nach wie vor zu erheblichen Schwierigkeiten bei dem Erkennen von Ähnlichkeiten.

\subsubsection{Erkennungsraten beim Quervergleich (\textit{Komplexe\\Bilder})}
Der in Abschnitt~\ref{sec:experimental_cc_images} durchgeführte Quervergleich der komplexen Bilder resultiert in einer
guten Fehlerverteilung für die einzelnen Algorithmen. Die gemessene Fehlerrate liegt dabei auch bei einem Threshold von 70\%
beständig weit unter der 10\%--Grenze.
\\
Der Fehlerbestand bei einer Stufe von 90\% als Threshold besteht größtenteils aus ähnlichen Bildern. Erst mit der Verringerung des
eingesetzten Thresholds wird der Fehlerbestand vor allem bei den Verfahren \textit{RADISH} sowie \textit{BMB} durch
unlogische, als fälschlich ähnlich markierte Vergleichspaare erweitert. Das Verhalten lässt sich auf die interne Arbeitsweise
der Algorithmen zurückführen.
\\[1em]
Ähnlich zueinander liegende Intensitätsverteilungen, bei zwei nicht gleichartigen Bildern, resultieren bei dem \textit{RADISH}--Ansatz
in einer ähnlich strukturellen Charakteristik innerhalb der Ergebnisse der \textit{Radon--Projektion}, wodurch schlussendlich
gleichartige Hashwerte erzielt werden (in Bezug auf den verwendeten Threshold).
\\
Die folgende Abbildung~\ref{fig:results_cc_radish} ist ein Beispiel für das Phänomen. 
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/Radish_Far.png}
	\caption{Übereinstimmende Intensitätsdistributionen (Eigene Darstellung)}
	\label{fig:results_cc_radish}
\end{figure}
\noindent
Die bei dem \textit{BMB}--Algorithmus entstehende Toleranz gegenüber der Fehlerrate steigt gleichzeitig mit dem Absinken des
Thresholds, sodass die Abweichungen zwischen den durchschnittlichen Gitterzellwerten und dem Gesamtdurchschnitt des Gitters
stufenweise akzeptiert werden.
\\[1em]
Der vermeintlich als gut bewertete Algorithmus ist die \textit{Wavelet}--Variante, die durchgehend eine Fehlerrate von \hbox{$FAR = 0$}
erzielte. In Kombinationen mit dem hohen Fehleranteil in der \textit{FRR} aus den vorherigen Tests lässt sich ableiten,
dass das allgemeine Erkennungsvermögen des \textit{Wavelet}--Ansatzes wenig überzeugend ist (ungeachtet ob gewollte oder nicht
gewollte Ähnlichkeitserkennungen). 

\subsection{Geschwindigkeitsanalysen}
Die Kategorie der Geschwindigkeitsanalyse beinhaltet zwei verschieden definierte Experimente hinsichtlich der Berechnungszeiten
der Algorithmen. Während der erste Testfall die reine Bearbeitungsgeschwindigkeit in bezugnehmend auf die vorhandene Datenkomplexität
analysiert, untersucht der zweite Test die prozentuale Effizienzsteigerung der vier Algorithmen gegenüber eines nativen Ansatzes.

\subsubsection{Berechnungszeiten der Algorithmen}
\label{sec:results_speed}
Wie in Abschnitt~\ref{sec:experimental_speed} definiert, wurden bei diesem Testfall nur die entstehenden Berechnungszeiten
in die Betrachtung mit einbezogen. Die Ladezeiten der einzelnen Bilddaten haben somit keinen Einfluss auf die gemessenen Werte.
\\
Bei der Analyse der internen Arbeitsweise der vier Algorithmen werden die zeitlichen Berechnungsdifferenzen schnell ersichtlich.
Während die Verfahren \textit{BMB} sowie \textit{RADISH} einfach strukturierte Pixeloperationen für die Extraktion der Merkmale
verwenden, kommen bei den Ansätzen \textit{DCT} und \textit{Wavelet} komplizierte und zeitaufwändige Operationen auf Pixelbasis
zum Einsatz (vgl.~\cite{ZAU10}).
\\[1em]
Unter der Berücksichtigung der erforderlichen Kommunikationszeit zwischen den Infrastrukturen \textit{Systemspeicher} sowie \textit{Festplatte},
ergibt sich das in Abbildung~\ref{fig:results_speed_ratio} ermittelte Durchschnittsverhältnis aus Lade-- und
Berechnungszeit je Bild bezüglich der Algorithmen.
\begin{figure}[H]
	\centering
	\framepicture[width=0.96\linewidth]{Pictures/speed_ratio.png}
	\caption{Geschwindigkeitsverhältnisse (Eigene Darstellung)}
	\label{fig:results_speed_ratio}
\end{figure}
\noindent
Aus dieser Betrachtungsweise lässt sich die benötigte Gesamtzeit für ein Vergleich zweier beliebiger Bilder ableiten:
\begin{equation}
	\label{eq:results_speed_total}
	Total = 2 * Ladezeit + 2 * Rechenzeit
\end{equation}
\noindent
Unter der Annahme, dass eines der beiden Bilder vor dem Vergleich bereits als bekannt angesehen werden kann, besteht die
Möglichkeit, den Hashwert für das Bild im Vorfeld zu berechnen und beispielsweise in einer Datenbank zu sichern.
\\
Daraus folgt eine Vereinfachung der Formel~\ref{eq:results_speed_total} zu:
\begin{equation}
	\begin{split}
		Total = 1 * Ladezeit + 1 * Rechenzeit \\
		+ 1 * Datenbankladezeit
	\end{split}
\end{equation}
\noindent
Aufgrund der deutlichen geringeren Dateigröße des abgespeicherten Hashwertes, konnten Geschwindigkeitssteigerungen bis zu
\hbox{$\sim49\%$} gemessen werden.

\subsubsection{Kreuzkorrelation mit vollständigem Informationsraum}
Das in Abschnitt~\ref{sec:experimental_speed_cc} durchgeführte Experiment determinierte einen gemeinsamen Bezugspunkt hinsichtlich
der Berechnungsgeschwindigkeiten der unterschiedlichen Algorithmen mittels einer der nativen Herangehensweise \textit{Kreuzkorrelation}.
\\
Eine Nebeneinanderstellung der sowohl in Abschnitt~\ref{sec:experimental_speed_cc} als auch in der Passage~\ref{sec:experimental_speed}
ermittelten linearen Trendlinien veranschaulicht den immensen Geschwindigkeitsverlust bei der Berechnung des Ähnlichkeitsmaßes mit Hilfe
des nativen Ansatzes.
\\
Die wiederholte Verdoppelung der Eingaberaumdimension führte zu einem Anstieg des Aufwandmultiplikators im Bereich von \hbox{$[5,16]$}.
Ein Bildpaar mit der Auflösung von 600x600px benötigt somit im Schnitt \hbox{$\sim38min\%$} für die Bestimmung der Ähnlichkeit (ungeachtet der
erzielten Erkennungsqualität). Bildmaterial von modernen Digitalkameras würden dementsprechend mehrere Stunden für den Berechnungsprozess
erfordern.
\\
Aufgrund der internen Funktionsweise der \textit{Kreuzkorrelation} sind Optimierungen, wie beispielsweise in dem vorherigen
Abschnitt~\ref{sec:results_speed} aufgezeigt, ausgeschlossen. Der Algorithmus ist auf die Vollständigkeit der originalen Dateninformationen
angewiesen, sodass zum Beispiel eine Zwischenspeicherung der Teilergebnisse nicht möglich ist.
\\[1em]
Ein direkter Vergleich zwischen den in Abschnitt~\ref{sec:experimental_speed} ermittelten Berechnungszeiten der einzelnen Algorithmen
und den Zeiten der \textit{Kreuzkorrelation} ergibt eine signifikante Leistungssteigerung, die in der nachstehenden
Tabelle~\ref{tab:result_speed_cc_ratio} aufgeführt ist. Der Zustand beschreibt ausschließlich die prozentualen Zeitverhältnisse des
verkleinerten Bildmaterials (Auflösung beträgt: 170x128px) gegenüber der Eingabedimension \textit{100x100px} sowie
des vergrößerten Bildmaterials (Auflösung beträgt: 2048x1536px) in Bezug auf die Dimension \textit{600x600px}.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|c|}
			\mytoprule
			\centering\bfseries Algorithmus & \bfseries 100x100px & \bfseries 600x600px
			\\
			\hline
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			\textit{RADISH} & 795\% & 8723,43\%
			\\
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			\textit{DCT} & 397,5\% & 4254,93\%
			\\
			\hline	
			%---------------------------------------------------------------------------------------------------------------------	
			\textit{Wavelet} & 6,68\% & 4138,04\%
			\\	
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			\textit{BMB} & 1590\% & 24828,24\%
			\\
			\hline
			\hline
			%---------------------------------------------------------------------------------------------------------------------	
			\textit{Durchschnitt} & 697,29\% & 10486,16\%
			\\																						
			%---------------------------------------------------------------------------------------------------------------------
			\mybottomrule			
		\end{tabular}
		\caption{Leistungssteigerungen gegenüber der \textit{Kreuzkorrelation} (Eigene Darstellung)}
		\label{tab:result_speed_cc_ratio}
	\end{center}
\end{table}	
\noindent
Die Tabelle~\ref{tab:result_speed_cc_ratio} unterstreicht zusätzlich, dass mit zunehmender Auflösung des Eingabebildmaterials die
Effizienz des nativen Verfahrens gegenüber den im vorliegenden Paper eingesetzten Algorithmen drastisch abfällt.